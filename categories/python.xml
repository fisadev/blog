<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Blog (fisa) (Posts about python)</title><link>http://blog.fisadev.com/</link><description></description><atom:link href="http://blog.fisadev.com/categories/python.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Tue, 15 Aug 2023 00:02:28 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Separate IO from algorithms</title><link>http://blog.fisadev.com/posts/separate-io-from-algorithms/</link><dc:creator>Juan Pedro Fisanotti</dc:creator><description>&lt;p&gt;This is an old post I wrote for the Machinalis blog. Machinalis was a company I worked at some years ago, that later on got acquired by Mercado Libre. The old post is no longer online, so I replicated it here to keep it somewhere on the web :)&lt;/p&gt;
&lt;section id="separate-io-from-algorithms"&gt;
&lt;h2&gt;Separate IO from algorithms&lt;/h2&gt;
&lt;p&gt;Being able to write clean, easy to maintain code is one of the most important skills a developer should have. And it isn’t an easy task to accomplish. We will often be presented with complex problems in which there is no clear “clean” solution. But at the same time, there are some simple practices that can help a lot in the path to better code.&lt;/p&gt;
&lt;p&gt;In this post we will talk about one of those practices: separating IO code from algorithms. It’s not rocket science, and many will probably find this obvious. But experience shows that it’s something too often overlooked, and when that happens, the code tends to become messy quite fast.&lt;/p&gt;
&lt;section id="a-not-so-real-example"&gt;
&lt;h3&gt;A not-so-real example&lt;/h3&gt;
&lt;p&gt;Let’s start with a hypothetical task (later on we will look at a more real example). It will be something quite simple, but bear in mind I’m using it as a vehicle to present some ideas. In real life I would probably just use &lt;code class="docutils literal"&gt;collections.Counter&lt;/code&gt; and the csv module :)&lt;/p&gt;
&lt;p&gt;Imagine we have a .csv file, in which each line has the name of a developer and the language he uses:&lt;/p&gt;
&lt;pre class="code text"&gt;&lt;a id="rest_code_f43999a86dca446bab0313fe3ca3957c-1" name="rest_code_f43999a86dca446bab0313fe3ca3957c-1"&gt;&lt;/a&gt;Guido Van Rossum,Python
&lt;a id="rest_code_f43999a86dca446bab0313fe3ca3957c-2" name="rest_code_f43999a86dca446bab0313fe3ca3957c-2"&gt;&lt;/a&gt;Dennis Ritchie,C
&lt;a id="rest_code_f43999a86dca446bab0313fe3ca3957c-3" name="rest_code_f43999a86dca446bab0313fe3ca3957c-3"&gt;&lt;/a&gt;Armin Ronacher,Python
&lt;a id="rest_code_f43999a86dca446bab0313fe3ca3957c-4" name="rest_code_f43999a86dca446bab0313fe3ca3957c-4"&gt;&lt;/a&gt;Larry Wall,Perl
&lt;a id="rest_code_f43999a86dca446bab0313fe3ca3957c-5" name="rest_code_f43999a86dca446bab0313fe3ca3957c-5"&gt;&lt;/a&gt;...
&lt;/pre&gt;&lt;p&gt;And we are asked to develop a small program that counts how many developers each language has. It must produce these results via standard output:&lt;/p&gt;
&lt;pre class="code text"&gt;&lt;a id="rest_code_b4dc6d2923e440fe95d6ae2285d6c318-1" name="rest_code_b4dc6d2923e440fe95d6ae2285d6c318-1"&gt;&lt;/a&gt;Python: 2
&lt;a id="rest_code_b4dc6d2923e440fe95d6ae2285d6c318-2" name="rest_code_b4dc6d2923e440fe95d6ae2285d6c318-2"&gt;&lt;/a&gt;Perl: 1
&lt;a id="rest_code_b4dc6d2923e440fe95d6ae2285d6c318-3" name="rest_code_b4dc6d2923e440fe95d6ae2285d6c318-3"&gt;&lt;/a&gt;C: 1
&lt;a id="rest_code_b4dc6d2923e440fe95d6ae2285d6c318-4" name="rest_code_b4dc6d2923e440fe95d6ae2285d6c318-4"&gt;&lt;/a&gt;...
&lt;/pre&gt;&lt;p&gt;The code we would write to solve the task could be something like this:&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a id="rest_code_f4f23829f7cb4b258d0060073dd54ae0-1" name="rest_code_f4f23829f7cb4b258d0060073dd54ae0-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;count_developers&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_path&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a id="rest_code_f4f23829f7cb4b258d0060073dd54ae0-2" name="rest_code_f4f23829f7cb4b258d0060073dd54ae0-2"&gt;&lt;/a&gt;    &lt;span class="n"&gt;quantities&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;
&lt;a id="rest_code_f4f23829f7cb4b258d0060073dd54ae0-3" name="rest_code_f4f23829f7cb4b258d0060073dd54ae0-3"&gt;&lt;/a&gt;    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;developers_file&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a id="rest_code_f4f23829f7cb4b258d0060073dd54ae0-4" name="rest_code_f4f23829f7cb4b258d0060073dd54ae0-4"&gt;&lt;/a&gt;        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;developers_file&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a id="rest_code_f4f23829f7cb4b258d0060073dd54ae0-5" name="rest_code_f4f23829f7cb4b258d0060073dd54ae0-5"&gt;&lt;/a&gt;            &lt;span class="n"&gt;developer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;language&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;','&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a id="rest_code_f4f23829f7cb4b258d0060073dd54ae0-6" name="rest_code_f4f23829f7cb4b258d0060073dd54ae0-6"&gt;&lt;/a&gt;            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;language&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;quantities&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a id="rest_code_f4f23829f7cb4b258d0060073dd54ae0-7" name="rest_code_f4f23829f7cb4b258d0060073dd54ae0-7"&gt;&lt;/a&gt;                &lt;span class="n"&gt;quantities&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;a id="rest_code_f4f23829f7cb4b258d0060073dd54ae0-8" name="rest_code_f4f23829f7cb4b258d0060073dd54ae0-8"&gt;&lt;/a&gt;            &lt;span class="n"&gt;quantities&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;a id="rest_code_f4f23829f7cb4b258d0060073dd54ae0-9" name="rest_code_f4f23829f7cb4b258d0060073dd54ae0-9"&gt;&lt;/a&gt;
&lt;a id="rest_code_f4f23829f7cb4b258d0060073dd54ae0-10" name="rest_code_f4f23829f7cb4b258d0060073dd54ae0-10"&gt;&lt;/a&gt;    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;quantity&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;quantities&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a id="rest_code_f4f23829f7cb4b258d0060073dd54ae0-11" name="rest_code_f4f23829f7cb4b258d0060073dd54ae0-11"&gt;&lt;/a&gt;        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="si"&gt;{l}&lt;/span&gt;&lt;span class="s1"&gt;: &lt;/span&gt;&lt;span class="si"&gt;{q}&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;quantity&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;And it works, it gets the job done. Even more: it looks like simple code, clean code.&lt;/p&gt;
&lt;p&gt;But it has some not-so-obvious problems:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;What if we want to write tests for it? That would be a problem: the tests would either have to create a file to use as input, and capture the standard output to check the results, or use lots of complex mocking to avoid the interaction with real files and real standard output.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What if at some point we need to count developers from a different source, like a json API response? We would need to create a .csv file just to be able to feed it into this function, even if our input data doesn’t come in a file.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What if we need to use the output in a different way instead of showing it to the user via standard output? This function forces the results to be shown in that particular way.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All these issues have the same root: our code is doing two things at the same time, that should be separated. Our program is dealing with the IO logic (reading files, showing results) and the algorithms itself (the “business logic”) in a single piece of code.&lt;/p&gt;
&lt;p&gt;In this simple example it would be trivial to refactor the code to solve any of those issues. But that kind of refactors (changes to the input and output formats of a piece of business logic) tends not to be so trivial in real life code.&lt;/p&gt;
&lt;p&gt;A better approach is then to follow that simple rule we mentioned in the beginning: to separate IO code from algorithms. Following that rule, our solution would look more like this:&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a id="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-1" name="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;read_developers_file&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_path&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a id="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-2" name="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-2"&gt;&lt;/a&gt;    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;developers_file&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a id="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-3" name="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-3"&gt;&lt;/a&gt;        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;','&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a id="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-4" name="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-4"&gt;&lt;/a&gt;                &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;developers_file&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;a id="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-5" name="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-5"&gt;&lt;/a&gt;
&lt;a id="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-6" name="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-6"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;count_developers&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;developers&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a id="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-7" name="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-7"&gt;&lt;/a&gt;    &lt;span class="n"&gt;quantities&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;
&lt;a id="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-8" name="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-8"&gt;&lt;/a&gt;    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;developer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;language&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;developers&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a id="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-9" name="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-9"&gt;&lt;/a&gt;        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;language&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;quantities&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a id="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-10" name="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-10"&gt;&lt;/a&gt;            &lt;span class="n"&gt;quantities&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;a id="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-11" name="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-11"&gt;&lt;/a&gt;        &lt;span class="n"&gt;quantities&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;a id="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-12" name="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-12"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;quantities&lt;/span&gt;
&lt;a id="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-13" name="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-13"&gt;&lt;/a&gt;
&lt;a id="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-14" name="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-14"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;show_report&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;quantities&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a id="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-15" name="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-15"&gt;&lt;/a&gt;    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;quantity&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;quantities&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a id="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-16" name="rest_code_f1b0af8c0d2941538ec88288f80fa2d0-16"&gt;&lt;/a&gt;        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="si"&gt;{l}&lt;/span&gt;&lt;span class="s1"&gt;: &lt;/span&gt;&lt;span class="si"&gt;{q}&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;quantity&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;In this new solution, we clearly divided our code in three blocks: the code dealing with the input file, the counting algorithm itself (business logic), and the code dealing with the output of the results. We can easily test the business logic without mocking or doing real IO. We can easily reuse the business logic in scenarios where the input or output formats are different. Even if we have to support input data coming from a stream, something quite difficult with the previous approach, we could achieve that with simple refactors. This separation leaves the door open for changes in a way the old code didn’t.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="a-real-example"&gt;
&lt;h3&gt;A real example&lt;/h3&gt;
&lt;p&gt;A very common scenario in which this rule is neglected, leading to really ugly code, slow and complex tests, and overall difficult to maintain code, are Django views. Developers too often write much of the business logic of their web apps right into the views. At first sight this doesn’t look “that bad”, the code is clean, simple. It’s just a view doing business stuff. But as we saw before, problems start to arise when we need to write tests, or reuse that business logic in slightly different scenarios.&lt;/p&gt;
&lt;p&gt;When writing the tests, people usually just rely on the &lt;code class="docutils literal"&gt;django.test.client&lt;/code&gt; to solve the “I need to do IO to test this logic” issue. The test client is great, it really solves the need of having to test a view. But the problem is: we shouldn’t be testing a view, when we just need to test a piece of business logic. We are doing lots of unnecessary extra work (url resolving, middlewares, etc), and complicating the test code, when it could have been just a function call.&lt;/p&gt;
&lt;p&gt;And as you can imagine, things get really messy when we need to reuse that business logic that’s buried inside the view.&lt;/p&gt;
&lt;p&gt;So, instead of writing views like this:&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a id="rest_code_a1fe5c8449154439883514ef3236290c-1" name="rest_code_a1fe5c8449154439883514ef3236290c-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;update_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;username&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a id="rest_code_a1fe5c8449154439883514ef3236290c-2" name="rest_code_a1fe5c8449154439883514ef3236290c-2"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;# logic to get the current score&lt;/span&gt;
&lt;a id="rest_code_a1fe5c8449154439883514ef3236290c-3" name="rest_code_a1fe5c8449154439883514ef3236290c-3"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;# logic to get the matches won&lt;/span&gt;
&lt;a id="rest_code_a1fe5c8449154439883514ef3236290c-4" name="rest_code_a1fe5c8449154439883514ef3236290c-4"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;# score = a little extra code calculating the new score&lt;/span&gt;
&lt;a id="rest_code_a1fe5c8449154439883514ef3236290c-5" name="rest_code_a1fe5c8449154439883514ef3236290c-5"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;# some more score updating&lt;/span&gt;
&lt;a id="rest_code_a1fe5c8449154439883514ef3236290c-6" name="rest_code_a1fe5c8449154439883514ef3236290c-6"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;# the last bits of the score update&lt;/span&gt;
&lt;a id="rest_code_a1fe5c8449154439883514ef3236290c-7" name="rest_code_a1fe5c8449154439883514ef3236290c-7"&gt;&lt;/a&gt;    &lt;span class="n"&gt;returnrender&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'score.html'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'score'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;score&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;We should always try to write views more similar to this:&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a id="rest_code_87c6f643883c4f198d3bb6c7001f4fff-1" name="rest_code_87c6f643883c4f198d3bb6c7001f4fff-1"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;score_logic&lt;/span&gt;
&lt;a id="rest_code_87c6f643883c4f198d3bb6c7001f4fff-2" name="rest_code_87c6f643883c4f198d3bb6c7001f4fff-2"&gt;&lt;/a&gt;
&lt;a id="rest_code_87c6f643883c4f198d3bb6c7001f4fff-3" name="rest_code_87c6f643883c4f198d3bb6c7001f4fff-3"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;update_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;username&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a id="rest_code_87c6f643883c4f198d3bb6c7001f4fff-4" name="rest_code_87c6f643883c4f198d3bb6c7001f4fff-4"&gt;&lt;/a&gt;    &lt;span class="n"&gt;score&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;score_logic&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;update_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;username&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a id="rest_code_87c6f643883c4f198d3bb6c7001f4fff-5" name="rest_code_87c6f643883c4f198d3bb6c7001f4fff-5"&gt;&lt;/a&gt;    &lt;span class="n"&gt;returnrender&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'score.html'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'score'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;score&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;/pre&gt;&lt;/section&gt;
&lt;section id="conclusion"&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;Separating IO from algorithms might sound like an obvious advice, but it isn’t, it’s a principle that is often overlooked. And specially in web apps, leading to test suites that take too much time to run, and code that is indeed very hard to maintain.&lt;/p&gt;
&lt;p&gt;It’s a simple rule, easy to follow, and it does prevent serious maintainability problems. So this is my advice: never again miss a chance to separate that function (or view) into dedicated IO and algorithms blocks. Your future self will be thankful :)&lt;/p&gt;
&lt;/section&gt;
&lt;/section&gt;</description><category>python</category><guid>http://blog.fisadev.com/posts/separate-io-from-algorithms/</guid><pubDate>Mon, 14 Feb 2022 20:55:50 GMT</pubDate></item><item><title>How to run Keras (Theano backend) with a Nvidia Optimus gpu using CUDA, under Ubuntu 16.04</title><link>http://blog.fisadev.com/posts/how-to-run-keras-theano-backend-with-a-nvidia-optimus-gpu-using-cuda-under-ubuntu-1604/</link><dc:creator>Juan Pedro Fisanotti</dc:creator><description>&lt;p&gt;I broke so many things trying to get this to work, that I need to write it down for my future self and any others who might need this.&lt;/p&gt;
&lt;p&gt;This tutorial explains how to get a Keras neural network to train using your gpu, or any Theano related code for that matter, but for the special scenario of having a Nvidia Optimus enabled gpu running under Ubuntu 16.04.
Other scenarios:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Under Ubuntu 16.04 and you have a Nvidia gpu which is not Optimus enabled? then some things might work, but the "Nvidia gpu drivers" section won't be useful to you.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Under a different distro or Ubuntu version? I would &lt;strong&gt;not&lt;/strong&gt; recommend trying this.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Have an non-Nvidia gpu? this &lt;strong&gt;won't work&lt;/strong&gt; at all.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Enough presentations, lets get to work.&lt;/p&gt;
&lt;section id="the-example"&gt;
&lt;h2&gt;0. The example&lt;/h2&gt;
&lt;p&gt;We will need a Keras example to check if things are working well.
Use the code from &lt;a class="reference external" href="https://github.com/fisadev/keras_experiments"&gt;this repo&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In that repo you will find a keras experiment (in one of the ipython notebooks), and a small script to check for gpu usage from Theano.
Both will be useful.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Remember&lt;/strong&gt; to create a virtualenv and &lt;strong&gt;install its dependencies&lt;/strong&gt; (from the &lt;code class="docutils literal"&gt;requirements.txt&lt;/code&gt;).
You can use wheels to speed up the process. And it requires &lt;strong&gt;python 3&lt;/strong&gt;.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="nvidia-gpu-drivers"&gt;
&lt;h2&gt;1. Nvidia gpu drivers&lt;/h2&gt;
&lt;p&gt;We need Ubuntu to be able to use our gpu.
To achieve that, we need both the gpu drivers and the Optimus drivers.
Thing is, Optimus drivers are kind of broken right now under Ubuntu 16.04.&lt;/p&gt;
&lt;p&gt;But we can get things working, with some small annoyances:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;p&gt;Disconnect any external/secondary monitors.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Install video and optimus drivers: &lt;code class="docutils literal"&gt;sudo apt install &lt;span class="pre"&gt;nvidia-361&lt;/span&gt; &lt;span class="pre"&gt;nvidia-prime&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Reboot your machine and login.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Open the "Nvidia X Server Settings" app, go to the "PRIME Profiles" section and choose "NVIDIA".&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Close the settings app.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Logout and login again, so the profile change can take effect.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;A small annoyance&lt;/strong&gt;: while the "NVIDIA" profile is active you cannot (at the moment) use a secondary screen.
It will crash your X server.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: remember to go back to the "Intel" profile whenever you don't want to use your gpu anymore, logout and login back for it to take effect.
Otherwise, your gpu will be using lots of power for nothing.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="cuda"&gt;
&lt;h2&gt;2. CUDA&lt;/h2&gt;
&lt;p&gt;We need to be able to do general purpose computation on our Nvidia gpu.
To achieve that, we need the CUDA toolkit.
Thing is, CUDA has no Ubuntu 16.04 package at the moment.&lt;/p&gt;
&lt;p&gt;But we can make things work. This is Linux, after all (thanks to Martin Thoma's &lt;a class="reference external" href="http://askubuntu.com/questions/799184/how-can-i-install-cuda-on-ubuntu-16-04"&gt;answer&lt;/a&gt;):&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;p&gt;Download CUDA from the &lt;a class="reference external" href="https://developer.nvidia.com/cuda-downloads"&gt;Nvidia website&lt;/a&gt;. Choose the Ubuntu 15.04 "runfile (local)" version.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Check the md5 sum with: &lt;code class="docutils literal"&gt;md5sum cuda_7.5.18_linux.run&lt;/code&gt;. Only continue if it is correct.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Run the installer and follow the instructions: &lt;code class="docutils literal"&gt;sudo sh cuda_7.5.18_linux.run &lt;span class="pre"&gt;--override&lt;/span&gt;&lt;/code&gt;. &lt;strong&gt;Make sure&lt;/strong&gt; that you say &lt;strong&gt;y&lt;/strong&gt; for the symbolic link, and &lt;strong&gt;n&lt;/strong&gt; to the video drivers installation.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Don't worry about the warning related to the non-installation of the video drivers.
The script is somewhat dumb and doesn't detect the drivers we installed on the previous section.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="gcc-and-g-versions"&gt;
&lt;h2&gt;3. Gcc and G++ versions&lt;/h2&gt;
&lt;p&gt;Guess what? Yes, more problems.&lt;/p&gt;
&lt;p&gt;CUDA requires gcc to be a version up to 4.9.
Later versions won't work.
Ubuntu 16.04 ships with gcc 5.4.&lt;/p&gt;
&lt;p&gt;But we can have both versions side by side, and trick CUDA to use the older versions with just some simple symlinks (thanks to &lt;a class="reference external" href="https://twitter.com/_zzzoom_/status/765720104868904964"&gt;charlie&lt;/a&gt; for the tip, the old solution was far more complicated).&lt;/p&gt;
&lt;pre class="code bash"&gt;&lt;a id="rest_code_224528d982f14f9dac3f4d8aef423c7e-1" name="rest_code_224528d982f14f9dac3f4d8aef423c7e-1"&gt;&lt;/a&gt;sudo apt-get install gcc-4.9 g++-4.9
&lt;a id="rest_code_224528d982f14f9dac3f4d8aef423c7e-2" name="rest_code_224528d982f14f9dac3f4d8aef423c7e-2"&gt;&lt;/a&gt;sudo ln -s /usr/bin/gcc-4.9  /usr/local/cuda/bin/gcc
&lt;a id="rest_code_224528d982f14f9dac3f4d8aef423c7e-3" name="rest_code_224528d982f14f9dac3f4d8aef423c7e-3"&gt;&lt;/a&gt;sudo ln -s /usr/bin/g++-4.9  /usr/local/cuda/bin/g++
&lt;a id="rest_code_224528d982f14f9dac3f4d8aef423c7e-4" name="rest_code_224528d982f14f9dac3f4d8aef423c7e-4"&gt;&lt;/a&gt;
&lt;a id="rest_code_224528d982f14f9dac3f4d8aef423c7e-5" name="rest_code_224528d982f14f9dac3f4d8aef423c7e-5"&gt;&lt;/a&gt;&lt;span class="c1"&gt;# Work around a glibc bug (according to the theano docs)&lt;/span&gt;
&lt;a id="rest_code_224528d982f14f9dac3f4d8aef423c7e-6" name="rest_code_224528d982f14f9dac3f4d8aef423c7e-6"&gt;&lt;/a&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; -e &lt;span class="s2"&gt;"\n[nvcc]\nflags=-D_FORCE_INLINES\n"&lt;/span&gt; &amp;gt;&amp;gt; ~/.theanorc
&lt;/pre&gt;&lt;/section&gt;
&lt;section id="testing"&gt;
&lt;h2&gt;4. Testing&lt;/h2&gt;
&lt;p&gt;Done! You should be able to run Theano things (including Keras neural networks) using your gpu.&lt;/p&gt;
&lt;p&gt;A simple way to check if that's true, is to run the &lt;code class="docutils literal"&gt;test_gpu.py&lt;/code&gt; script from the example repo.
But don't just "run" it.
You need to tell Theano "hey, I want you to use my shiny cuda gpu".
To achieve that, run the script like this (inside your virtualenv):&lt;/p&gt;
&lt;pre class="code bash"&gt;&lt;a id="rest_code_7bbfa04c5d434523898f5f3089b52fe2-1" name="rest_code_7bbfa04c5d434523898f5f3089b52fe2-1"&gt;&lt;/a&gt;&lt;span class="nv"&gt;THEANO_FLAGS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"mode=FAST_RUN,device=gpu,floatX=float32,cuda.root=/usr/local/cuda/"&lt;/span&gt; python test_gpu.py
&lt;/pre&gt;&lt;p&gt;If everything is working, it should quickly run and output something which ends with: &lt;code class="docutils literal"&gt;Used the gpu&lt;/code&gt;.
If instead it takes a long time (~1 minute) and ends with &lt;code class="docutils literal"&gt;Used the cpu&lt;/code&gt;, then something is not working.&lt;/p&gt;
&lt;p&gt;If that worked, then you can try the full example and play a little with it (should be able to run all lines without errors):&lt;/p&gt;
&lt;pre class="code bash"&gt;&lt;a id="rest_code_20a534a1545249cc824d15924f9fb575-1" name="rest_code_20a534a1545249cc824d15924f9fb575-1"&gt;&lt;/a&gt;&lt;span class="nv"&gt;THEANO_FLAGS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"mode=FAST_RUN,device=gpu,floatX=float32,cuda.root=/usr/local/cuda/"&lt;/span&gt; ipython notebook
&lt;/pre&gt;&lt;/section&gt;</description><category>cuda</category><category>keras</category><category>machine learning</category><category>programming</category><category>python</category><category>ubuntu</category><guid>http://blog.fisadev.com/posts/how-to-run-keras-theano-backend-with-a-nvidia-optimus-gpu-using-cuda-under-ubuntu-1604/</guid><pubDate>Wed, 21 Sep 2016 01:58:35 GMT</pubDate></item></channel></rss>